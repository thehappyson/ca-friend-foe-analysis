{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friend-Foe Analysis - Quick Start Demo\n",
    "\n",
    "This notebook demonstrates the complete pipeline for analyzing visual differences between \"Us\" (ingroup) and \"Them\" (outgroup) in Nazi propaganda films.\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "1. **Frame Extraction** - Extract frames from video files\n",
    "2. **Annotation** - Label frames as 'us' or 'them'\n",
    "3. **Feature Extraction** - Extract visual features (lighting, composition, etc.)\n",
    "4. **Classification** - Train ML model to distinguish groups\n",
    "5. **Analysis** - Analyze feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our modules\n",
    "from frame_extraction import extract_frames_uniform, get_video_info\n",
    "from annotation import FrameAnnotator, create_annotation_template, show_frame\n",
    "from feature_extraction import VisualFeatureExtractor, extract_features_from_directory\n",
    "from model import FriendFoeClassifier, train_and_evaluate_pipeline\n",
    "\n",
    "# Visualization settings\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Frame Extraction\n",
    "\n",
    "Extract frames from video files. For the POC, we'll extract a small number of uniformly distributed frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Extract frames from a video file\n",
    "# Replace with your actual video path\n",
    "\n",
    "VIDEO_PATH = \"path/to/your/video.mp4\"  # Change this!\n",
    "\n",
    "# Check if video exists\n",
    "if Path(VIDEO_PATH).exists():\n",
    "    # Get video info\n",
    "    info = get_video_info(VIDEO_PATH)\n",
    "    print(\"Video info:\", info)\n",
    "    \n",
    "    # Extract 50 uniformly distributed frames\n",
    "    output_dir = \"../data/raw/demo_frames\"\n",
    "    frames = extract_frames_uniform(VIDEO_PATH, output_dir, num_frames=50)\n",
    "    print(f\"Extracted {len(frames)} frames\")\n",
    "else:\n",
    "    print(f\"Video not found: {VIDEO_PATH}\")\n",
    "    print(\"Please update VIDEO_PATH with your actual video file path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Annotation Template\n",
    "\n",
    "Create a CSV template for annotating frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create annotation template\n",
    "frame_dir = \"../data/raw/demo_frames\"\n",
    "annotation_file = \"../data/annotated/demo_annotations.csv\"\n",
    "\n",
    "if Path(frame_dir).exists():\n",
    "    create_annotation_template(frame_dir, annotation_file)\n",
    "else:\n",
    "    print(f\"Frame directory not found: {frame_dir}\")\n",
    "    print(\"Please extract frames first (Step 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2b: Interactive Annotation (Simple Version)\n",
    "\n",
    "Annotate frames interactively. For each frame:\n",
    "- Label: 'us', 'them', 'neutral', or 'unclear'\n",
    "- Optionally add notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotator\n",
    "annotator = FrameAnnotator(annotation_file)\n",
    "\n",
    "# Get list of frames to annotate\n",
    "frame_dir = Path(\"../data/raw/demo_frames\")\n",
    "if frame_dir.exists():\n",
    "    frames = sorted(list(frame_dir.glob(\"*.jpg\")))\n",
    "    print(f\"Found {len(frames)} frames to annotate\")\n",
    "    \n",
    "    # Example: annotate first frame\n",
    "    if len(frames) > 0:\n",
    "        show_frame(frames[0])\n",
    "        \n",
    "        # Manually annotate (you would do this for each frame)\n",
    "        # annotator.add_annotation(frames[0], label='us', confidence=0.9, notes='Heroic pose')\n",
    "        # annotator.save()\n",
    "else:\n",
    "    print(\"Frame directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Annotation Instructions\n",
    "\n",
    "For the POC, you can manually edit the CSV file:\n",
    "\n",
    "1. Open `data/annotated/demo_annotations.csv` in Excel/LibreOffice\n",
    "2. For each frame, fill in the `label` column:\n",
    "   - `us` - Ingroup (idealized Germans, heroes, Volksgemeinschaft)\n",
    "   - `them` - Outgroup (Jews, Communists, enemies)\n",
    "   - `neutral` - Neither (background, landscape, etc.)\n",
    "   - `unclear` - Can't determine\n",
    "3. Save the CSV file\n",
    "\n",
    "**Note:** For training, you need at least 20-30 frames labeled as 'us' and 'them'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature Extraction\n",
    "\n",
    "Extract visual features from all frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "frame_dir = \"../data/raw/demo_frames\"\n",
    "features_csv = \"../data/features/demo_features.csv\"\n",
    "\n",
    "if Path(frame_dir).exists():\n",
    "    features_df = extract_features_from_directory(frame_dir, features_csv)\n",
    "    print(\"\\nFeature extraction complete!\")\n",
    "    print(f\"Extracted {len(features_df)} feature vectors with {len(features_df.columns)-1} features each\")\n",
    "    \n",
    "    # Show sample features\n",
    "    print(\"\\nSample features:\")\n",
    "    display(features_df.head())\n",
    "else:\n",
    "    print(f\"Frame directory not found: {frame_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train Classifier\n",
    "\n",
    "Train a Random Forest classifier to distinguish 'us' from 'them'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have annotations\n",
    "features_csv = \"../data/features/demo_features.csv\"\n",
    "annotations_csv = \"../data/annotated/demo_annotations.csv\"\n",
    "\n",
    "if Path(features_csv).exists() and Path(annotations_csv).exists():\n",
    "    # Load and check annotations\n",
    "    annotations_df = pd.read_csv(annotations_csv)\n",
    "    label_counts = annotations_df['label'].value_counts()\n",
    "    print(\"Label distribution:\")\n",
    "    print(label_counts)\n",
    "    \n",
    "    # Check if we have enough labeled data\n",
    "    us_count = len(annotations_df[annotations_df['label'] == 'us'])\n",
    "    them_count = len(annotations_df[annotations_df['label'] == 'them'])\n",
    "    \n",
    "    if us_count >= 10 and them_count >= 10:\n",
    "        print(f\"\\nSufficient labeled data: {us_count} 'us' samples, {them_count} 'them' samples\")\n",
    "        print(\"Proceeding with training...\\n\")\n",
    "        \n",
    "        # Train and evaluate\n",
    "        output_dir = \"../results\"\n",
    "        classifier, results = train_and_evaluate_pipeline(\n",
    "            features_csv,\n",
    "            annotations_csv,\n",
    "            test_size=0.2,\n",
    "            output_dir=output_dir\n",
    "        )\n",
    "    else:\n",
    "        print(f\"\\nInsufficient labeled data:\")\n",
    "        print(f\"  'us' samples: {us_count} (need at least 10)\")\n",
    "        print(f\"  'them' samples: {them_count} (need at least 10)\")\n",
    "        print(\"\\nPlease annotate more frames in the CSV file.\")\n",
    "else:\n",
    "    print(\"Features or annotations not found. Please complete previous steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Analyze Results\n",
    "\n",
    "Examine feature importance to understand which visual characteristics distinguish the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature importance results\n",
    "importance_file = \"../results/feature_importance.csv\"\n",
    "\n",
    "if Path(importance_file).exists():\n",
    "    importance_df = pd.read_csv(importance_file)\n",
    "    \n",
    "    print(\"Top 10 Most Important Features:\")\n",
    "    print(importance_df.head(10))\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_features = importance_df.head(15)\n",
    "    sns.barplot(data=top_features, y='feature', x='importance')\n",
    "    plt.title('Most Important Visual Features for Friend-Foe Distinction')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Results not found. Please train the model first (Step 4).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Guide\n",
    "\n",
    "### Key Features to Analyze:\n",
    "\n",
    "**Lighting Features:**\n",
    "- `low_key_ratio` - High values = dark, dramatic lighting (often for villains)\n",
    "- `high_key_ratio` - High values = bright, even lighting (often for heroes)\n",
    "- `contrast` - High contrast = dramatic, low contrast = soft\n",
    "\n",
    "**Composition Features:**\n",
    "- `vertical_symmetry` - Symmetrical compositions often convey power/order\n",
    "- `center_brightness` - Center focus draws attention to subject\n",
    "- `edge_density` - More edges = busy/chaotic vs clean/simple\n",
    "\n",
    "**Color Features:**\n",
    "- `saturation_mean` - Desaturated (grayscale-like) vs vibrant colors\n",
    "- `hue_mean` - Warm tones (red/yellow) vs cool tones (blue/green)\n",
    "\n",
    "### Expected Findings:\n",
    "\n",
    "Based on propaganda research, \"Us\" (ingroup) typically features:\n",
    "- High-key lighting (bright, even)\n",
    "- Symmetrical compositions\n",
    "- Low-angle shots (convey power)\n",
    "- Clean, orderly framing\n",
    "\n",
    "\"Them\" (outgroup) typically features:\n",
    "- Low-key lighting (dark, shadowy)\n",
    "- Asymmetrical compositions\n",
    "- High-angle shots (diminish subject)\n",
    "- Cluttered, chaotic framing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Expand dataset**: Add more films, more frames\n",
    "2. **Improve annotations**: More careful labeling, inter-annotator agreement\n",
    "3. **Advanced features**: Add face detection, pose estimation, scene detection\n",
    "4. **Deep learning**: Try pre-trained CNNs (VGG, ResNet) for feature extraction\n",
    "5. **Qualitative analysis**: Select example frames that show clear visual patterns\n",
    "6. **Write paper**: Document findings in the structured report format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
